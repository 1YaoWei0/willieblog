---
title: 微软【AI-900】考试准备系列博客二
comments: true
date: 2025-02-25 21:04:43
tags:
categories:
 - ai-900
description: 本文记录着【AI-900】入门认证考试的学习笔记
---

## Microsoft Azure AI 基础

### 第一部分

#### 什么是机器学习

机器学习起源于数据的统计和数学建模。 机器学习的基本理念是使用过去观测到的数据来预测未知的结果或值。 例如：

- 冰淇淋店的老板可能会使用某个应用，结合历史销售和天气记录，根据天气预报来预测他们在某一天可能会售出多少个冰淇淋。
- 医生可能会使用以往患者的临床数据来运行自动测试，以根据体重、血糖水平和其他测量值等因素来预测新患者是否有患糖尿病的风险。
- 南极研究人员可能会利用过去的观测值，根据鸟类脚蹼、喙和其他物理属性的测量，自动识别不同的企鹅物种（例如阿德利企鹅、白眉企鹅或帽带企鹅）。

#### 机器学习作为一种函数

由于机器学习基于数学和统计学，因此通常会使用数学术语来思考机器学习模型。 从根本上讲，机器学习模型是一种软件应用程序，它封装一个函数用于根据一个或多个输入值计算输出值。 定义该函数的过程称为训练。 定义函数后，可以使用它在称为“推理”的过程中预测新值。

让我们探讨一下训练和推理所涉及的步骤。

{% asset_img "machine-learning.png" "machine learn" %}

1. 训练数据由过去的观测值组成。 在大多数情况下，观测值包括观测到的事物的属性或特征，以及要训练模型来预测的事物的已知值（称为标签）。
    在数学术语中，你经常会看到使用速记变量名称 x 引用的特征，以及使用 y 引用的标签。 通常，观测值由多个特征值组成，因此 x 实际上是一个向量（包含多个值的数组），如下所示：[x1,x2,x3,...]。
    为了澄清这一点，让我们分析前面所述的示例：
    - 在冰淇淋销售场景中，我们的目标是训练一个可以根据天气预测冰淇淋销售数量的模型。 当天的天气测量值（温度、降雨量、风速等）是特征 (x)，每日售出的冰淇淋数量是标签 (y)。
    - 在医疗场景中，目标是根据患者的临床测量值预测患者是否有患糖尿病的风险。 患者的测量值（体重、血糖水平等）是特征 (x)，患糖尿病的可能性（例如，1 表示有风险，0 表示没有风险）是标签 (y)。
    - 在南极研究场景中，我们希望根据企鹅的物理属性来预测其物种。 企鹅的关键测量值（脚蹼的长度、喙的宽度等）是特征 (x)，物种（例如，0 表示阿德利企鹅，1 表示白眉企鹅，2 表示帽带企鹅）是标签 (y)。

2. 将对数据应用某种算法，以尝试确定特征与标签之间的关系，然后泛化这种关系，以便针对 x 执行计算来计算 y。 使用的具体算法取决于要解决的预测问题的类型（稍后会详细介绍），但基本原 则是尝试将一个函数拟合到数据，其中的特征值可用于计算标签

3. 算法的结果是一个模型，该模型将算法派生的计算封装为函数 - 我们称之为 f。 采用数学表示法：

y = f(x)

4. 完成训练阶段后，训练的模型可用于推理。 模型本质上是一个软件程序，可以封装训练过程生成的函数。 你可以输入一组特征值，并接收相应标签的预测结果作为输出。 由于模型的输出是函数计算的预测值而不是观测值，因此你经常会看到函数的输出显示为 ŷ（戏称为“y-hat”）

### 第二部分

#### 机器学习类型

机器学习有多种类型，必须根据尝试预测的内容应用适当的类型。 下图显示了常见机器学习类型的细目。

{% asset_img "machine-learning-types.png" "machine learn type" %}

##### 监督式机器学习

监督式机器学习是机器学习算法的一个通用术语，其中训练数据包括特征值和已知标签值。 监督式机器学习用于通过确定过去观测值中特征与标签之间的关系来训练模型，以便将来可以预测特征的未知标签。

###### 回归

回归是监督式机器学习的一种形式，其中模型预测的标签是数值。 例如：

- 给定一天销售的冰淇淋数量，基于温度、降雨量和风速。
- 物业的销售价格，基于物业大小（以平方英尺为单位）、所含卧室数量及所在位置的社会经济指标。
- 汽车燃油效率（以英里/加仑为单位），基于发动机大小、重量、宽度、高度和长度。

###### 分类

分类是监督式机器学习的一种形式，其中标签表示一个分类或类。 有两种常见的分类场景。

**二元分类**
在二元分类中，标签确定观察到的项是（或不是）特定类的实例。 换句话说，二元分类模型预测两个互斥结果中的一个。 例如：

- 基于体重、年龄、血糖水平等临床指标，患者是否有患糖尿病的风险。
- 基于收入、信用记录、年龄和其他因素，银行客户是否会拖欠贷款。
- 基于人口统计属性和过去的购买情况，邮寄列表客户是否会对营销产品/服务做出积极响应。

在所有这些示例中，模型为单个可能类预测二进制 true/false 或积极/消极预测。

**多类分类**

多类分类扩展了二元分类，以预测表示多个可能类之一的标签。 例如，

- 企鹅的物种（阿德利企鹅、巴布亚企鹅或帽带企鹅），基于身体测量。
- 电影的流派（喜剧、恐怖、爱情、冒险或科幻），基于演员、导演和预算。

在涉及一组已知多个类的场景中，多类分类用于预测互斥标签。 例如，一只企鹅不能同时是巴布亚企鹅和阿德利企鹅。 但是，还可以使用一些算法来训练多标签分类模型，其中对于单个观测值可能有多个有效标签。 例如，一部电影可能同时被归类为科幻和喜剧。

##### 非监督式机器学习
非监督式机器学习涉及使用仅包含特征值且没有任何已知标签的数据来训练模型。 非监督式机器学习算法确定训练数据中观测值的特征之间的关系。

###### 群集/聚类分析
非监督式机器学习最常见的形式是聚类分析。 聚类分析算法基于观测值的特征识别观测值之间的相似性，并将它们分组到离散群集中。 例如：

- 根据花的大小、叶数和花瓣数量，对类似的花进行分组。
- 根据人口统计属性和购买行为，确定类似客户的组。

在某些方面，聚类分析类似于多类分类；因为它将观侧值分类为离散组。 区别在于，使用分类时，你已经知道训练数据中的观测值所属的类；因此，该算法的工作原理是确定特征与已知分类标签之间的关系。 在聚类分析中，没有以前已知的分类标签，算法完全基于特征的相似性对数据观测值进行分组。

在某些情况下，聚类分析用于确定在训练分类模型之前存在的类集。 例如，可以使用聚类分析将客户细分到多个组，然后对这些组进行分析，以识别不同的客户类并对其进行分类（高价值 - 低交易量、经常购买小额产品等）。 然后，可以使用分类来标记聚类分析结果中的观测值，并使用标记的数据来训练预测新客户可能属于哪个客户类别的分类模型。

### 第三部分

#### 回归

回归模型经过训练，基于包括特征和已知标签的训练数据来预测数值标签值。 训练回归模型（或者实际上，任何监督式机器学习模型）的过程涉及多次迭代，在这些迭代中，你使用适当的算法（通常带有一些参数化设置）来训练模型，评估模型的预测性能，并通过使用不同的算法和参数重复训练过程来优化模型，直到达到可接受的预测准确性级别。

{% asset_img "supervised-training.png" "supervised training" %}

此图显示了监督式机器学习模型的训练过程的四个关键元素：

- 拆分训练数据（随机）以创建用于训练模型的数据集，同时保留要用于验证已训练模型的一部分数据。
- 使用算法以将训练数据拟合到模型。 对于回归模型，使用回归算法，例如线性回归。
- 使用保留的验证数据，通过预测特征的标签来测试模型。
- 将验证数据集中的已知实际标签与模型预测的标签进行比较。 然后，聚合预测的标签值和实际的标签值之间的差异以计算一个指标，该指标指示模型对验证数据的预测准确度。

每次训练、验证和评估迭代后，可以使用不同的算法和参数重复该过程，直到达到可接受的评估指标。

#### 示例 - 回归

让我们通过一个简化的示例来探索回归，在该示例中，我们将训练一个模型以基于单个特征值 (x) 预测数值标签 (y)。 大多数实际场景涉及多个特征值，这增加了一些复杂性；但原理是相同的。

对于示例，让我们继续使用之前讨论过的冰淇淋销售场景。 对于特征，我们将考虑温度（假设该值是给定日期的最高温度），我们希望训练模型以预测的标签是当天售出的冰淇淋数量。 我们将从一些历史数据开始，其中包括每日温度 (x) 和冰淇淋销售额 (y) 的记录：

| 温度 (x) | 冰淇淋销售额 (y) |
| -------- | ---------------- |
| 51       | 1                |
| 52       | 0                |
| 67       | 14               |
| 65       | 14               |
| 70       | 23               |
| 69       | 20               |
| 72       | 23               |
| 75       | 26               |
| 73       | 22               |
| 81       | 30               |
| 78       | 26               |
| 83       | 36               |

##### 训练回归模型

首先，我们将拆分数据，并使用其中一部分数据来训练模型。 下面是训练数据集：

| 温度 (x) | 冰淇淋销售额 (y) |
| -------- | ---------------- |
| 51       | 1                |
| 65       | 14               |
| 69       | 20               |
| 72       | 23               |
| 75       | 26               |
| 81       | 30               |

若要深入了解这些 x 和 y 值如何相互关联，我们可以将它们绘制为沿两个轴的坐标，如下所示：

{% asset_img "scatter-plot.png" "scatter plot" %}

现在，我们已准备好将算法应用于训练数据，并将其拟合到将运算应用于 x 以计算 y 的函数。 其中一种算法是线性回归，它的工作原理是派生一个函数，该函数通过 x 和 y 值的交点生成一条直线，同时最小化直线和绘制点之间的平均距离，如下所示：

{% asset_img "regression-line.png" "regression line" %}

这条直线是函数的可视表示形式，其中直线的斜率描述了如何针对给定的 x 值计算 y 值。 这条直线在 50 处与 x 轴相交，因此当 x 为 50 时，y 为 0。 从绘图中的轴标记可以看出，直线倾斜，使得沿 x 轴每增加 5，沿 y 轴就会增加 5；因此当 x 为 55 时，y 为 5；当 x 为60时，y 为 10，依此类推。 若要针对给定的 x 值计算 y 值，函数只需减去 50；换句话说，函数可以如下表示：

f(x) = x-50

可以使用此函数来预测任何给定温度下一天售出的冰淇淋数量。 例如，假设天气预报告诉我们，明天将是 77 度。 我们可以应用模型来计算 77-50，并预测我们明天将销售 27 个冰淇淋。

但是我们的模型有多准确呢？

##### 评估回归模型

为了验证模型并评估其预测效果，我们保留了一些已知标签 (y) 值的数据。 下面是我们保留的数据：

| 温度 (x) | 冰淇淋销售额 (y) |
| -------- | ---------------- |
| 52       | 0                |
| 67       | 14               |
| 70       | 23               |
| 73       | 22               |
| 78       | 26               |
| 83       | 36               |

可以使用模型根据特征 (x) 值来预测此数据集中每个观测值的标签；然后，将预测的标签 (ŷ) 与已知的实际标签值 (y) 进行比较。

使用前面训练的模型（该模型封装函数 f(x) = x-50），可生成以下预测：

| 温度 (x) | 实际销售额 (y) |
| -------- | -------------- |
| 52       | 0              |
| 67       | 14             |
| 70       | 23             |
| 73       | 22             |
| 78       | 26             |
| 83       | 36             |

我们可以针对特征值绘制预测标签和实际标签，如下所示：

{% asset_img "regression-variance.png" "regression variance" %}

预测标签由模型计算，因此它们位于函数线上，但是由函数计算的 ŷ 值与来自验证数据集的实际 y 值之间存在一些差异；这在绘图上表示为 ŷ 值和 y 值之间的线，显示预测值与实际值的差距。

##### 回归评估指标

根据预测值和实际值之间的差异，可以计算用于评估回归模型的一些常见指标。

平均绝对误差 (MAE)

此示例中的方差指示每个预测错误的冰淇淋数量。 预测是高于还是低于实际值无关紧要（例如，-3 和 +3 都表示方差为 3）。 此指标被称为每个预测的绝对误差，并且可以被总结为整个验证集的平均绝对误差 (MAE)。

在冰淇淋示例中，绝对误差（2、3、3、1、2 和 3）的平均值为 2.33。

###### 均方误差 (MSE)

平均绝对误差指标同等地考虑预测标签和实际标签之间的所有差异。 然而，相比误差较少但较大的模型，一个始终误差较小的模型可能更可取。 生成“放大”较大误差的指标的一种方法是对单个误差求平方，并计算平方值的平均值。 此指标被称为均方误差 (MSE)。

在我们的冰淇淋示例中，绝对值平方（4、9、9、1、4 和 9）的平均值为 6。

###### 均方根误差 (RMSE)

均方误差有助于考虑误差的幅度，但是因为它对误差值进行平方，所以得到的指标不再代表标签测量的量。 换句话说，我们可以说模型的 MSE 为 6，但这并不能衡量它在被错误预测的冰淇淋数量方面的准确性；6 只是一个数字分数，表示验证预测中的错误级别。

如果要根据冰淇淋的数量来衡量误差，我们需要计算 MSE 的平方根；不出所料，这生成了一个名为均方根误差的指标。 在本例中，为 √6，即 2.45（冰淇淋）。

###### 决定系数 (R2)

到目前为止，所有指标都比较预测值与实际值之间的差异，以评估模型。 然而，在现实中，模型考虑到了冰淇淋日销售额中的一些自然随机差异。 在线性回归模型中，训练算法拟合一条直线，使函数和已知标签值之间的平均方差最小化。 决定系数（通常称为 R2 或 R 平方）是一种指标，用于测量验证结果中可由模型解释的方差比例，而不是验证数据的某些异常方面（例如，由于当地节日，某一天的冰淇淋销售量非常不寻常）。

R2 的计算比前面的指标更复杂。 它将预测标签和实际标签之间的平方差之和与实际标签值和实际标签值的平均值之间的平方差之和进行比较，如下所示：

R2 = 1- ∑(y-ŷ)2 ÷ ∑(y-ȳ)2

如果这看起来很复杂，不要太担心；大多数机器学习工具都可以为你计算指标。 重要的一点是，结果是一个介于 0 和 1 之间的值，该值描述了模型所解释的方差的比例。 简单来说，此值越接近 1，模型就越拟合验证数据。 对于冰淇淋回归模型，根据验证数据计算的 R2 为 0.95。

### 第四部分

#### 二元分类

分类与回归一样，是一种受监督的机器学习技术，因此遵循相同的适用于训练、验证和评估模型的迭代过程。 用于训练分类模型的算法不是像回归模型那样计算数值，而是计算类分配的概率值以及用于评估模型性能的评估指标，将预测类与实际类进行比较。

二元分类算法用于训练模型，该模型可预测单个类的两个可能标签之一。 本质上是预测 true 或 false。 在大多数实际方案中，用于训练和验证模型的数据观测值包含多个特征 (x) 值和一个为 1 或 0 的 y 值。

#### 示例 - 二元分类

为了了解二元分类的工作原理，我们来看一个简化的示例，该示例使用单个特征 (x) 来预测标签 y 是 1 还是 0。 在此示例中，我们将使用患者的血糖水平来预测患者是否患有糖尿病。 下面是用于训练模型的数据：

| 血糖 (x) | **糖尿病？ (y)** |
| -------- | ---------------- |
| 67       | 0                |
| 103      | 1                |
| 114      | 1                |
| 72       | 0                |
| 116      | 1                |
| 65       | 0                |

##### 训练二元分类模型

为了训练模型，我们将使用一种算法将训练数据拟合为一个函数，该函数计算类标签为 true（换句话说，患者有糖尿病）的概率。 概率以某个 0.0 到 1.0 之间的值来度量，使得所有可能的类的总概率为 1.0。 例如，如果一名患者患糖尿病的概率为 0.7，那么该患者未患糖尿病的相应概率为 0.3。

有许多可用于二元分类的算法，例如逻辑回归，它会导出值在 0.0 到 1.0 之间的 sigmoid（S 形）函数，如下所示：

{% asset_img "sigmoid-plot.png" "sigmoid plot" %}

> 尽管名称如此，但在机器学习中，逻辑回归用于分类，而不是用于回归。 重点是它生成的函数的逻辑性质，该函数描述了下限值和上限值（用于二元分类时为 0.0 和 1.0）之间的 S 形曲线。

该算法生成的函数描述了 x 为给定值时 y 为 true (y=1) 的概率。 从数学上来说，可以这样表达该函数：

f(x) = P(y=1 | x)

就训练数据中六个观测值中的三个来说，我们知道 y 肯定为 true，因此就这些观测值来说，y=1 的概率为 1.0；就其他三个来说，我们知道 y 肯定为 false，因此 y=1 的概率为 0.0。 S 形曲线描绘了概率分布情况，因此在曲线上标出 x 的值就可以确定 y 为 1 的相应概率。

该图还包含一条水平线，指示基于此函数的模型将预测 true (1) 或 false (0) 的阈值。 阈值位于 y (P(y) = 0.5) 的中间点。 对于此点或高于此点的任何值，模型会预测 true (1)；而对于低于此点的任何值，模型会预测 false (0)。 例如，对于血糖水平为 90 的患者，该函数将得出的概率值为 0.9。 由于 0.9 高于阈值 0.5，因此模型会预测 true (1) - 换句话说，预测患者患有糖尿病。

##### 评估二元分类模型

与回归一样，在训练二元分类模型时，我们会保留一个随机数据子集来验证训练后的模型。 假设我们保留以下数据来验证糖尿病分类器：

| 血糖 (x) | 糖尿病？ (y) |
| -------- | ------------ |
| 66       | 0            |
| 107      | 1            |
| 112      | 1            |
| 71       | 0            |
| 87       | 1            |
| 89       | 1            |

将我们之前派生的逻辑函数应用于 x 值会生成下图。

{% asset_img "classification-predictions.png" "classification predictions" %}

模型为每个观测值生成预测标签 1 或 0，具体取决于函数计算出的概率是高于阈值还是低于阈值。 然后，我们可以将预测的类标签 (ŷ) 与实际的类标签 (y) 进行比较，如下所示：

| 血糖 (x) | 实际的糖尿病诊断 (y) | 预测的糖尿病诊断 (ŷ) |
| -------- | -------------------- | -------------------- |
| 66       | 0                    | 0                    |
| 107      | 1                    | 1                    |
| 112      | 1                    | 1                    |
| 71       | 0                    | 0                    |
| 87       | 1                    | 0                    |
| 89       | 1                    | 1                    |

##### 二元分类评估指标

计算二元分类模型的评估指标的第一步通常是为每个可能的类标签创建正确预测和错误预测的数量矩阵：

{% asset_img "binary-confusion-matrix.png" "binary confusion matrix" %}

此可视化效果称为混淆矩阵，它显示预测总计，其中：

- ŷ=0 且 y=0：真阴性 (TN)
- ŷ=1 且 y=0：假阳性 (FP)
- ŷ=0 且 y=1：假阴性 (FN)
- ŷ=1 且 y=1：真阳性 (TP)

混淆矩阵的排列是这样的：正确 (true) 预测显示在从左上角到右下角的对角线上。 通常情况下，颜色强度用于指示每个单元格中的预测数量，因此快速浏览一下预测良好的模型应该就会看出深阴影对角线趋势。

###### 精确度

可以根据混淆矩阵计算出的最简单指标是准确度 - 模型正确预测的比例。 准确度的计算方式如下：

(TN+TP) ÷ (TN+FN+FP+TP)

在我们的糖尿病示例中，计算如下：

(2+3) ÷ (2+1+0+3)

= 5 ÷ 6

= **0.83**

因此，就我们的验证数据来说，糖尿病分类模型在 83% 的情况下产生正确的预测。

准确度一开始似乎是评估模型的一个很好的指标，但请考虑这一点。 假设 11% 的人口患有糖尿病。 可以创建一个始终预测 0 的模型，即使在没有真正尝试通过评估患者的特征来区分患者的情况下，其准确率仍可达到 89%。 我们真正需要的是更深入地了解模型在预测 1（代表阳性病例）和 0（代表阴性病例）时的表现。

###### 召回率

召回率是度量此模型正确识别的阳性病例比例的指标。 换句话说，与确实患有糖尿病的患者人数相比，此模型预测有多少人患有糖尿病？

召回率的公式为：

TP ÷ (TP+FN)

就我们的糖尿病示例来说：

3 ÷ (3+1)

= 3 ÷ 4

= **0.75**

因此，我们的模型正确地将 75% 的糖尿病患者识别为糖尿病患者。

###### 精度

精准率是与召回率类似的指标，但度量的是预测为阳性病例且真实标签实际上也为阳性的比例。 换句话说，在模型预测患有糖尿病的患者中，实际患有糖尿病的患者的比例是多少？

精准率公式为：

TP ÷ (TP+FP)

就我们的糖尿病示例来说：

3 ÷ (3+0)

= 3 ÷ 3

= **1.0**

因此，在我们的模型预测的患有糖尿病的患者中，100% 的人确实患有糖尿病。

###### F1 分数

F1 分数是一个结合了召回率和精准率的总体指标。 F1 分数的公式为：

(2 x 精准率 x 召回率) ÷ (精准率 + 召回率)

就我们的糖尿病示例来说：

(2 x 1.0 x 0.75) ÷ (1.0 + 0.75)

= 1.5 ÷ 1.75

**= 0.86**

###### 曲线下面积 (AUC)

召回率的另一个名称是真阳性率 (TPR)。此外还有一个称为假阳性率 (FPR) 的等效指标，其计算公式为 FP÷(FP+TN)。 我们已经知道，在使用阈值 0.5 时，我们的模型的 TPR 为 0.75。我们可以使用 FPR 的公式计算出 0÷2 的值为 0。

当然，如果我们更改模型预测 true (1) 的阈值，则会影响阳性和阴性预测的数量，因此会更改 TPR 和 FPR 指标。 这些指标通常用于通过绘制接收方操作特征 (ROC) 曲线来评估模型，该曲线会比较 0.0 到 1.0 之间的每个可能阈值的 TPR 和 FPR：

{% asset_img "roc-chart.png" "roc chart" %}

完美模型的 ROC 曲线会沿左侧的 TPR 轴直线上升，然后穿过顶部的 FPR 轴。 由于曲线的绘图面积为 1x1，因此该完美曲线下的面积将为 1.0（这意味着模型始终是正确的）。 相比之下，从左下角到右上角的对角线表示通过随机猜测二进制标签获得的结果；产生的曲线下面积为 0.5。 换句话说，给定两个可能的类标签，你可以合理预期猜对的概率为 50%。

就我们的糖尿病模型来说，会生成上面的曲线，曲线下面积 (AUC) 指标为 0.875。 由于 AUC 高于 0.5，因此我们可以得出结论：该模型在预测患者是否患有糖尿病方面比随机猜测的表现更好。
